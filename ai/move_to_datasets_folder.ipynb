{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b51c8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from glob import glob\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./code2idx.csv\")\n",
    "\n",
    "\n",
    "dataset_path = \"/home/j-j10b102/datasets/{}\"\n",
    "root = \"/home/j-j10b102/166.약품식별_인공지능_개발을_위한_경구약제_이미지_데이터/01.데이터/1.Training/{}/단일경구약제_5000종/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0004ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_seqs = [199303108,200400485,201500041,200300406,200301805,201403321   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4311076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move(item_seq):\n",
    "    item = df[df[\"item_seq\"]==item_seq]\n",
    "    \n",
    "    group_folders = []\n",
    "\n",
    "    image_group_folder = item[\"group\"].iloc[0]\n",
    "    \n",
    "\n",
    "    label_group_folder = image_group_folder.split(\"_\")\n",
    "\n",
    "    label_group_folder[0] = \"TL\"\n",
    "\n",
    "    label_group_folder = \"_\".join(label_group_folder)\n",
    "\n",
    "    group_folders.append(image_group_folder)\n",
    "\n",
    "    group_folders.append(label_group_folder)\n",
    "    \n",
    "    print(group_folders)\n",
    "    \n",
    "    \n",
    "    \n",
    "    arr = {}\n",
    "    \n",
    "    for idx, group_folder in enumerate(group_folders):\n",
    "\n",
    "        drug_n_folder = item[\"drug_n\"].iloc[-1]\n",
    "        data = {}\n",
    "        if idx == 0:\n",
    "            data[\"drug_n_folder\"] = drug_n_folder\n",
    "            data[\"path\"] = \"원천데이터\"\n",
    "            data[\"extension\"] = \"png\"\n",
    "            data[\"dtype\"] = \"images\"\n",
    "            \n",
    "        else:\n",
    "            data[\"drug_n_folder\"] = drug_n_folder+\"_json\"\n",
    "            data[\"path\"] = \"라벨링데이터\"\n",
    "            data[\"extension\"] = \"txt\"\n",
    "            data[\"dtype\"] = \"labels\"\n",
    "        data[\"group_folder\"] = group_folder\n",
    "        arr[idx] = data\n",
    "        \n",
    "    for key, data in arr.items():\n",
    "        path = root.format(data[\"path\"])\n",
    "        path = path+data[\"group_folder\"]+\"/\"+data[\"drug_n_folder\"]\n",
    "        \n",
    "        train_folder = path+\"/\"+data[\"dtype\"]+\"/train\"\n",
    "        val_folder = path+\"/\"+data[\"dtype\"]+\"/val\"\n",
    "        \n",
    "#         print(train_folder)\n",
    "        \n",
    "        dataset_train = dataset_path.format(data[\"dtype\"])+\"/train/\"\n",
    "        dataset_val = dataset_path.format(data[\"dtype\"])+\"/val/\"\n",
    "        if not os.path.exists(dataset_train):\n",
    "            os.makedirs(dataset_train)\n",
    "            \n",
    "        if not os.path.exists(dataset_val):\n",
    "            os.makedirs(dataset_val)\n",
    "        \n",
    "        train_files = glob(train_folder+\"/*.\"+data[\"extension\"])\n",
    "        val_files  = glob(val_folder+\"/*.\"+data[\"extension\"])\n",
    "        \n",
    "        \n",
    "#         print(len(train_files))\n",
    "#         for file in train_files:\n",
    "#             os.remove(file)\n",
    "            \n",
    "#         for file in val_files:\n",
    "#             os.remove(file)\n",
    "#         print(dataset_train)\n",
    "        for file in train_files:\n",
    "            filename, ext = os.path.splitext(file)\n",
    "            filename = filename.split(\"/\")[-1]+ext\n",
    "            dst_file = dataset_train+filename\n",
    "            \n",
    "            shutil.copy(file, dst_file)\n",
    "            \n",
    "        for src_file in val_files:\n",
    "            filename, ext = os.path.splitext(src_file)\n",
    "            filename = filename.split(\"/\")[-1]+ext\n",
    "            dst_file = dataset_val+filename\n",
    "            \n",
    "            shutil.copy(src_file,dst_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fef8c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TS_3_단일', 'TL_3_단일']\n",
      "-----\n",
      "['TS_40_단일', 'TL_40_단일']\n",
      "-----\n",
      "['TS_74_단일', 'TL_74_단일']\n",
      "-----\n",
      "['TS_7_단일', 'TL_7_단일']\n",
      "-----\n",
      "['TS_7_단일', 'TL_7_단일']\n",
      "-----\n",
      "['TS_15_단일', 'TL_15_단일']\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# move(item_seqs[0])\n",
    "\n",
    "for item_seq in item_seqs:\n",
    "    move(item_seq)\n",
    "    print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f535e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_empty_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        return len(lines) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acfe9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for label_file in glob(\"../datasets/labels/val/*\"):\n",
    "#     print(\"label: \", label_file)\n",
    "    if is_empty_file(label_file):\n",
    "        print(f\"{label_file} is an empty file.\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fcab89",
   "metadata": {},
   "source": [
    "# val/labels의 파일이름과 val/images의 파일이름이 동일한지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8f772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = set()\n",
    "\n",
    "for img_file in glob(\"../datasets/images/val/*\"):\n",
    "    filename, _ = os.path.splitext(img_file)\n",
    "    filename = filename.split(\"/\")[-1]\n",
    "    image_files.add(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cfafbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_files = set()\n",
    "for label_file in glob(\"../datasets/labels/val/*\"):\n",
    "    filename, _ = os.path.splitext(label_file)\n",
    "    filename = filename.split(\"/\")[-1]\n",
    "    label_files.add(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b6f095c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_files.intersection(image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb4608d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_files.difference(image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dc25bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526a6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
